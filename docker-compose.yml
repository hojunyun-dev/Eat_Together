version: '3.8'

services:
  # Spring Boot 애플리케이션
  eat-together-app:
    build: .
    container_name: eat_together
    ports:
      - "8080:8080"
    networks:
      - monitoring
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_started
      es01:
        condition: service_healthy
    environment:
      - spring.data.redis.host=redis
      - spring.data.redis.port=${REDIS_PORT}
      - spring.datasource.url=jdbc:mysql://mysql:${MYSQL_PORT}/${MYSQL_DBNAME}
      - spring.datasource.username=${MYSQL_USERNAME}
      - spring.datasource.password=${MYSQL_PASSWORD}
      - spring.elasticsearch.uris=http://es01:9200,http://es02:9200,http://es03:9200
    env_file:
      - .env
    labels:
      co.elastic.logs/enabled: "true"


  # MySQL 데이터베이스
  mysql:
    image: mysql:8.0
    container_name: mysql_db
    ports:
      - "3307:3306"
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DBNAME}
    volumes:
      - mysql_data:/var/lib/mysql
    networks:
      - monitoring
    healthcheck:
      test: [ "CMD", "mysqladmin", "ping", "-h", "localhost" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Redis 캐시 서버
  redis:
    image: redis:7.0-alpine
    container_name: redis-cache
    networks:
      - monitoring
    ports:
      - "6379:6379"

  # --------------------
  # Elasticsearch 클러스터 (3노드)
  # --------------------
  es01:
    build:
      context: .
      dockerfile: Dockerfile.elasticsearch
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=es-cluster
      - discovery.seed_hosts=es02,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - xpack.security.enabled=false        # 운영 전환 시 true + 인증/SSL 구성 권장
      - ES_JAVA_OPTS=-Xms512m -Xmx512m      # 로컬 리소스에 맞게 조정
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes: # volumes 미설정 시 프로그램 시작 시 마다 ES Index가 날아가 검색 불가
      - esdata01:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"   # 호스트 공개는 es01만
    healthcheck:
      test: [ "CMD-SHELL", "curl --silent --fail http://localhost:9200/_cluster/health || exit 1" ]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks: [ monitoring ]

  es02:
    build:
      context: .
      dockerfile: Dockerfile.elasticsearch
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=es-cluster
      - discovery.seed_hosts=es01,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ulimits:
      memlock: { soft: -1, hard: -1 }
    volumes: # volumes 미설정 시 프로그램 시작 시 마다 ES Index가 날아가 검색 불가
      - esdata02:/usr/share/elasticsearch/data
    networks: [ monitoring ]

  es03:
    build:
      context: .
      dockerfile: Dockerfile.elasticsearch
    container_name: es03
    environment:
      - node.name=es03
      - cluster.name=es-cluster
      - discovery.seed_hosts=es01,es02
      - cluster.initial_master_nodes=es01,es02,es03
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ulimits:
      memlock: { soft: -1, hard: -1 }
    volumes: # volumes 미설정 시 프로그램 시작 시 마다 ES Index가 날아가 검색 불가
      - esdata03:/usr/share/elasticsearch/data
    networks: [ monitoring ]

  # Elasticsearch 초기 인덱스 생성(클러스터 올라온 뒤 실행)
  init-elasticsearch:
    image: curlimages/curl:7.83.1
    container_name: init_elasticsearch
    depends_on:
      es01: { condition: service_healthy }
      es02: { condition: service_healthy }
      es03: { condition: service_healthy }
    networks: [ monitoring ]
    command: >
      sh -c "
        echo 'waiting for ES cluster to be at least yellow...';
        until curl --silent --fail 'http://es01:9200/_cluster/health?wait_for_status=yellow&timeout=120s' > /dev/null; do
          sleep 5;
        done;
        curl -X PUT 'http://es01:9200/store' -H 'Content-Type: application/json' -d '{
          \"settings\": {
            \"analysis\": {
              \"tokenizer\": {
                \"nori_tokenizer\": {
                  \"type\": \"nori_tokenizer\",
                  \"decompound_mode\": \"mixed\"
                }
              },
              \"analyzer\": {
                \"nori\": {
                  \"type\": \"custom\",
                  \"tokenizer\": \"nori_tokenizer\",
                  \"filter\": [\"lowercase\"]
                }
              }
            }
          },
          \"mappings\": {
            \"properties\": {
              \"id\": { \"type\": \"keyword\" },
              \"normalizationName\": { \"type\": \"text\", \"analyzer\": \"nori\" }
            }
          }
        }'
      "

  # 모니터링 스택
  mysqld_exporter:
    image: prom/mysqld-exporter
    container_name: mysqld_exporter
    ports:
      - "9104:9104"
    depends_on:
      - mysql
    command:
      - "--mysqld.username=${MYSQL_USERNAME}:${MYSQL_PASSWORD}"
      - "--mysqld.address=mysql:${MYSQL_PORT}"
    networks:
      - monitoring

  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter
    command: --redis.addr=redis:6379
    depends_on:
      - redis
    networks:
      - monitoring
    ports:
      - "9121:9121"

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./prometheus/:/etc/prometheus/
    ports:
      - "9090:9090"
    networks:
      - monitoring
    depends_on:
      - redis-exporter
      - eat-together-app
      - mysqld_exporter

  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./grafana_data:/var/lib/grafana
    networks:
      - monitoring

  # kibana 추가
  kibana1:
    image: docker.elastic.co/kibana/kibana:8.18.1
    container_name: kibana1
    environment:
      ELASTICSEARCH_HOSTS: '["http://es01:9200","http://es02:9200","http://es03:9200"]'
      XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY: ${KIBANA_ENCRYPTED_SAVED_OBJECTS_KEY}
      XPACK_REPORTING_ENCRYPTIONKEY: ${KIBANA_REPORTING_KEY}
      XPACK_SECURITY_ENCRYPTIONKEY: ${KIBANA_SECURITY_KEY}
    ports:
      - "5601:5601"
    depends_on:
      es01: { condition: service_healthy }
    networks: [ monitoring ]

  kibana2:
    image: docker.elastic.co/kibana/kibana:8.18.1
    container_name: kibana2
    environment:
      ELASTICSEARCH_HOSTS: '["http://es01:9200","http://es02:9200","http://es03:9200"]'
      XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY: ${KIBANA_ENCRYPTED_SAVED_OBJECTS_KEY}
      XPACK_REPORTING_ENCRYPTIONKEY: ${KIBANA_REPORTING_KEY}
      XPACK_SECURITY_ENCRYPTIONKEY: ${KIBANA_SECURITY_KEY}
    # 로컬 테스트면 포트를 다르게, 운영은 LB 뒤에 둡니다.
    ports:
      - "5602:5601"
    depends_on:
      es01: { condition: service_healthy }
    networks: [ monitoring ]

  # Filebeat (로그 수집기) 추가
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.18.1
    container_name: filebeat
    user: root
    depends_on:
      es01: { condition: service_healthy }
    networks: [ monitoring ]
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro   # Filebeat 설정(읽기전용)
      - filebeat-data:/usr/share/filebeat/data                         # 레지스트리(오프셋) 영속화
      - /var/lib/docker/containers:/var/lib/docker/containers:ro       # 도커 컨테이너 로그 경로
      - /var/run/docker.sock:/var/run/docker.sock                      # 도커 오토디스커버용 소켓
    command: [ "-e", "--strict.perms=false" ]        # -e: stdout 로깅, 권한 체크 완화

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "22181:2181"
    networks:
      - monitoring

  kafka1:
    image: confluentinc/cp-kafka:7.5.3
    depends_on:
      - zookeeper
    ports:
      - "19092:19092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:9092,EXTERNAL://localhost:19092
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
    networks:
      - monitoring

  kafka2:
    image: confluentinc/cp-kafka:7.5.3
    depends_on:
      - zookeeper
    ports:
      - "19093:19093"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:9093,EXTERNAL://localhost:19093
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
    networks:
      - monitoring

  kafka3:
    image: confluentinc/cp-kafka:7.5.3
    depends_on:
      - zookeeper
    ports:
      - "19094:19094"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka3:9094,EXTERNAL://localhost:19094
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
    networks:
      - monitoring

  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8989:8080"
    restart: always
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka1:9092,kafka2:9093,kafka3:9094
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    networks:
      - monitoring

networks:
  monitoring:
    driver: bridge

volumes:
  grafana_data:
  mysql_data:
  filebeat-data:
  esdata01:
  esdata02:
  esdata03: